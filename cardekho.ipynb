{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb796c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ba173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cardekho_imputated.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5978cca8",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cefb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d626e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['car_name','brand','Unnamed: 0'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bbaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O' ]\n",
    "print(\"Number of numeric features : \", len(num_features))\n",
    "\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print(f\"Number of ctegorical features : {len(cat_features)}\")\n",
    "\n",
    "disc_features = [feature for feature in num_features if len(df[feature].unique()) <= 25] \n",
    "print(f\"Number of discrete features : {len(disc_features)}\" )\n",
    "\n",
    "conti_features = [feature for feature in num_features if feature not in disc_features]\n",
    "print(f\"Number of continuous features : {len(conti_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent and Dependent feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('selling_price',axis=1)\n",
    "y = df['selling_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "label = LabelEncoder()\n",
    "\n",
    "X['model'] = label.fit_transform(X['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88895f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_features = [feature for feature in X.columns if X[feature].dtype != 'O']\n",
    "onehot_columns = ['seller_type','fuel_type','transmission_type']\n",
    "\n",
    "onehot_encoder = OneHotEncoder(drop='first')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"OneHotEncoder\",onehot_encoder,onehot_columns),\n",
    "    (\"StandardScaler\",scaler,num_features)\n",
    "],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de263b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true,predicted):\n",
    "    mse = mean_squared_error(true,predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(true,predicted)\n",
    "    r2score = r2_score(true,predicted)\n",
    "\n",
    "    return rmse,mae,r2score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\" : LinearRegression(),\n",
    "    \"Ridge\" : Ridge(),\n",
    "    \"Lasso\" : Lasso(),\n",
    "    \"RandomForest\" : RandomForestRegressor(),\n",
    "    \"DecisionTree\" : DecisionTreeRegressor(),\n",
    "    \"KNN\" : KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "    # make predictions\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluate train and test dataset\n",
    "\n",
    "    model_train_rmse, model_train_mae, model_train_r2score = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_rmse, model_test_mae, model_test_r2score = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "\n",
    "    print(\"Model Performance for Training Set\")\n",
    "    print(\"RMSE : {:.4f}\".format(model_train_rmse))\n",
    "    print(\"MAE : {:.4f}\".format(model_train_mae))\n",
    "    print(\"R2 Score  : {:.4f}\".format(model_train_r2score))\n",
    "\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    print(\"Model Performance for Test Set\")\n",
    "    print(\"RMSE : {:.4f}\".format(model_test_rmse))\n",
    "    print(\"MAE : {:.4f}\".format(model_test_mae))\n",
    "    print(\"R2 Score  : {:.4f}\".format(model_test_r2score))\n",
    "\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1cfbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\" : [50,100,200,300,500,1000],\n",
    "    \"criterion\" : [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "    \"min_samples_split\" : [0,1,2,3,5,10],\n",
    "    \"max_features\" :[5,7,\"auto\",8],\n",
    "    \"max_depth\" : [5,10,15,None,8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebdf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "randomCV = RandomizedSearchCV(estimator=models['RandomForest'],param_distributions=rf_params,cv=5,n_iter=100,verbose=True)\n",
    "\n",
    "randomCV.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\" : RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "    # make predictions\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluate train and test dataset\n",
    "\n",
    "    model_train_rmse, model_train_mae, model_train_r2score = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_rmse, model_test_mae, model_test_r2score = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "\n",
    "    print(\"Model Performance for Training Set\")\n",
    "    print(\"RMSE : {:.4f}\".format(model_train_rmse))\n",
    "    print(\"MAE : {:.4f}\".format(model_train_mae))\n",
    "    print(\"R2 Score  : {:.4f}\".format(model_train_r2score))\n",
    "\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    print(\"Model Performance for Test Set\")\n",
    "    print(\"RMSE : {:.4f}\".format(model_test_rmse))\n",
    "    print(\"MAE : {:.4f}\".format(model_test_mae))\n",
    "    print(\"R2 Score  : {:.4f}\".format(model_test_r2score))\n",
    "\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
